{
  "llm": {
    "provider": "ollama"
  },
  "ollama": {
    "model": "deepseek-coder:33b-instruct-q4_K_M",
    "endpoint": "http://localhost:11434",
    "temperature": 0.3
  },
  "anthropic": {
    "model": "claude-3-haiku-20240307",
    "temperature": 0.5
  },
  "gemini": {
    "model": "gemini-1.5-flash",
    "temperature": 0.7
  },
  "verification": {
    "strictness": "medium",
    "quantitative_weight": 0.6,
    "qualitative_weight": 0.4
  }
}
